import { NodeExecutor } from './NodeExecutor';
import { DAGNode, ExecutionContext } from '../types';
import { llmService, LLMMessage } from '../services/LLMService';

export interface AgentNodeConfig {
  model?: string;
  temperature?: number;
  systemPrompt?: string;
  maxTokens?: number;
}

/**
 * AgentNodeExecutor - æ‰§è¡Œ AI Agent èŠ‚ç‚¹
 * è°ƒç”¨ OpenAI API è¿›è¡Œå¯¹è¯
 */
export class AgentNodeExecutor extends NodeExecutor {
  async execute(
    node: DAGNode,
    context: ExecutionContext,
    _engine: unknown
  ): Promise<unknown> {
    console.log('[AgentNodeExecutor] â–¶ï¸ execute()', node.id);
    const config = node.data as AgentNodeConfig;
    console.log('[AgentNodeExecutor] ğŸ“‹ é…ç½®:', { model: config.model, temperature: config.temperature });
    
    // è·å–ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡ºä½œä¸ºè¾“å…¥
    const inputs = this.collectInputs(node, context);
    console.log('[AgentNodeExecutor] ğŸ“¥ ä¸Šæ¸¸è¾“å…¥:', Object.keys(inputs));
    
    // æ„å»ºæ¶ˆæ¯åˆ—è¡¨
    const messages: LLMMessage[] = [];
    
    // æ·»åŠ ç³»ç»Ÿæç¤ºè¯
    if (config.systemPrompt) {
      messages.push({ role: 'system', content: config.systemPrompt });
    }
    
    // æ·»åŠ ä¸Šä¸‹æ–‡å†å²ï¼ˆå¦‚æœæœ‰ï¼‰
    const contextHistory = context.variables.get('__messages') as LLMMessage[] | undefined;
    if (contextHistory && Array.isArray(contextHistory)) {
      messages.push(...contextHistory);
    }
    
    // æ·»åŠ å½“å‰è¾“å…¥
    const userMessage = this.buildUserMessage(inputs);
    messages.push({ role: 'user', content: userMessage });
    
    // è°ƒç”¨ LLM
    console.log('[AgentNodeExecutor] ğŸ¤– è°ƒç”¨ LLM...', { msgCount: messages.length });
    const response = await llmService.chat(messages, {
      model: config.model || 'GLM-4.7',
      temperature: config.temperature ?? 0.7,
      maxTokens: config.maxTokens || 2000,
    });
    console.log('[AgentNodeExecutor] âœ… LLM å“åº”:', { contentLength: response.content.length });
    
    // ä¿å­˜æ¶ˆæ¯å†å²åˆ°ä¸Šä¸‹æ–‡
    const updatedHistory = [...messages, { role: 'assistant' as const, content: response.content }];
    context.variables.set('__messages', updatedHistory);
    
    // è¿”å›ç»“æœ
    const result = {
      content: response.content,
      usage: response.usage,
      model: config.model || 'GLM-4.7',
    };
    console.log('[AgentNodeExecutor] ğŸ‰ æ‰§è¡Œå®Œæˆ', result);
    return result;
  }
  
  /**
   * æ”¶é›†ä¸Šæ¸¸èŠ‚ç‚¹çš„è¾“å‡º
   */
  private collectInputs(node: DAGNode, context: ExecutionContext): Record<string, unknown> {
    console.log('[AgentNodeExecutor] ğŸ“¥ collectInputs()', { nodeInputs: node.inputs, availableOutputs: Array.from(context.nodeOutputs.keys()) });
    const inputs: Record<string, unknown> = {};
    
    for (const inputNodeId of node.inputs) {
      const output = context.nodeOutputs.get(inputNodeId);
      if (output !== undefined) {
        inputs[inputNodeId] = output;
        console.log('[AgentNodeExecutor]   â†’ è¾“å…¥:', inputNodeId);
      }
    }
    
    console.log('[AgentNodeExecutor] ğŸ“Š æ”¶é›†å®Œæˆ:', Object.keys(inputs));
    return inputs;
  }
  
  /**
   * æ„å»ºç”¨æˆ·æ¶ˆæ¯
   */
  private buildUserMessage(inputs: Record<string, unknown>): string {
    const inputValues = Object.values(inputs);
    
    if (inputValues.length === 0) {
      return 'è¯·å¼€å§‹ä»»åŠ¡ã€‚';
    }
    
    if (inputValues.length === 1) {
      const input = inputValues[0];
      if (typeof input === 'string') {
        return input;
      }
      if (typeof input === 'object' && input !== null) {
        return (input as any).content || JSON.stringify(input);
      }
      return String(input);
    }
    
    // å¤šä¸ªè¾“å…¥æ—¶åˆå¹¶
    return inputValues.map((input, index) => {
      const content = typeof input === 'object' && input !== null 
        ? ((input as any).content || JSON.stringify(input))
        : String(input);
      return `[è¾“å…¥ ${index + 1}]\n${content}`;
    }).join('\n\n');
  }
}
